{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac14eb42",
   "metadata": {},
   "source": [
    "# Import Required Libraries\n",
    "Import all necessary libraries, including dotenv, langchain modules, and the ingest_urls_to_chromadb function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a468af42",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.embeddings.fastembed import FastEmbedEmbeddings\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from vectorstore import ingest_urls_to_chromadb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9361d70d",
   "metadata": {},
   "source": [
    "# Load Environment Variables\n",
    "Use the dotenv library to load environment variables, such as CHROMA_DB_DIR and OPENAI_API_KEY."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022c8653",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "persist_directory = os.getenv(\"CHROMA_DB_DIR\", \"./chroma_db\")\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "if not openai_api_key:\n",
    "    raise ValueError(\"OPENAI_API_KEY environment variable not set. If you're running this in Jupyter Notebook, ensure that the .env file is in the current working directory and that the notebook kernel was restarted after creating or modifying the .env file. You can also manually set the environment variable in a cell using os.environ['OPENAI_API_KEY'] = 'your-key'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1efb5b9f",
   "metadata": {},
   "source": [
    "# Define Helper Functions\n",
    "Define any helper functions, such as a function to handle errors or validate inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc732d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_prompt(prompt: str):\n",
    "    if not prompt or not isinstance(prompt, str):\n",
    "        raise ValueError(\"Prompt must be a non-empty string.\")\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1753103e",
   "metadata": {},
   "source": [
    "# Ingest URLs into ChromaDB\n",
    "Call the ingest_urls_to_chromadb function to ingest URLs into the ChromaDB vector store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa9e1d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 1969, which is longer than the specified 1024\n",
      "Created a chunk of size 1188, which is longer than the specified 1024\n",
      "Created a chunk of size 1188, which is longer than the specified 1024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ingestion complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\LabFiles\\PersonalizedLearningAssistant\\backend\\vectorstore\\__init__.py:85: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
      "  vectorstore.persist()\n"
     ]
    }
   ],
   "source": [
    "urls = [\n",
    "    \"https://www.nationalgeographic.com/latest-stories\",\n",
    "    \"https://www.smithsonianmag.com/smart-news/\",\n",
    "    \"https://www.bbc.com/news/science_and_environment\",\n",
    "    \"https://www.nasa.gov/news/all-news/\",\n",
    "    \"https://blog.khanacademy.org/\",\n",
    "    \"https://www.history.com/this-day-in-history\",\n",
    "    \"https://www.cdc.gov/media/index.html\",\n",
    "    \"https://www.nih.gov/news-events/news-releases\",\n",
    "    \"https://www.scientificamerican.com/section/news/\",\n",
    "    \"https://www.unicef.org/press-releases\"\n",
    "]\n",
    "ingest_urls_to_chromadb(urls, persist_directory=persist_directory)\n",
    "print(\"Ingestion complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2664b5c",
   "metadata": {},
   "source": [
    "# Initialize Vector Store\n",
    "Initialize the Chroma vector store with embeddings and the persist directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10fc4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = FastEmbedEmbeddings()\n",
    "vectorstore = Chroma(\n",
    "    embedding_function=embeddings,\n",
    "    persist_directory=persist_directory\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1532c670",
   "metadata": {},
   "source": [
    "# Retrieve Relevant Documents\n",
    "Use the vector store's retriever to fetch relevant documents based on the input prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca8e5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"What is the latest news about Mars exploration?\"\n",
    "validate_prompt(prompt)\n",
    "retriever = vectorstore.as_retriever()\n",
    "relevant_docs = retriever.get_relevant_documents(prompt)\n",
    "print(f\"Found {len(relevant_docs)} relevant documents.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9186265f",
   "metadata": {},
   "source": [
    "# Prepare Prompt Template\n",
    "Create a ChatPromptTemplate for the LLM, ensuring it includes the context and user prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0c4073",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"You are a kind and knowledgeable teacher chatbot designed to help children learn.\\n\\nYour job is to provide safe, clear, and age-appropriate explanations.\\n\\nNEVER make up answers. You MUST ONLY use the information provided in the <Context> section.\\n\\nIf the answer is not directly found in the context, say:\\n\\\"I'm not sure about that based on what I have here.\\\"\\n\\nAlways respond kindly, simply, and concisely.\\n\\nCONTEXT:\\n\\n{context}\"\"\"),\n",
    "    (\"human\", \"\"\"The student is {age_group} years old.\\nThey asked this question:\\n{prompt}\"\"\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de68b8d0",
   "metadata": {},
   "source": [
    "# Run Retrieval-Augmented Generation (RAG) Chain\n",
    "Invoke the RAG chain with the context, prompt, and age group, and handle the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2becda",
   "metadata": {},
   "outputs": [],
   "source": [
    "age_group = \"Middle School [12-14]\"\n",
    "model = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    api_key=openai_api_key\n",
    ")\n",
    "chain = create_stuff_documents_chain(\n",
    "    llm=model,\n",
    "    prompt=chat_prompt\n",
    ")\n",
    "result = chain.invoke({\n",
    "    \"context\": \"\\n\\n\".join([doc.page_content for doc in relevant_docs]),\n",
    "    \"prompt\": prompt,\n",
    "    \"age_group\": age_group\n",
    "})\n",
    "if isinstance(result, dict) and \"output\" in result:\n",
    "    print(\"Summary:\", result[\"output\"])\n",
    "elif isinstance(result, str):\n",
    "    print(\"Summary:\", result)\n",
    "else:\n",
    "    print(\"Unexpected result:\", result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
